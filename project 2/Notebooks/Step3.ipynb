{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36d512bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib  # For saving the model\n",
    "\n",
    "#from library.sb_utils import save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1caca261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current and historical datasets\n",
    "\n",
    "current_data_file_path = '../data/processed/data_final.csv'  # Update the path to your file\n",
    "data = pd.read_csv(current_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c921a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>gold_medal</th>\n",
       "      <th>silver_medal</th>\n",
       "      <th>bronze_medal</th>\n",
       "      <th>total_medal</th>\n",
       "      <th>type_olympic</th>\n",
       "      <th>host_flag</th>\n",
       "      <th>Country_</th>\n",
       "      <th>gold_medal_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_enrollment_ratio</th>\n",
       "      <th>secondary_enrollment_ratio</th>\n",
       "      <th>tertiary_enrollment_ratio</th>\n",
       "      <th>internet_penetration</th>\n",
       "      <th>mobile_penetration</th>\n",
       "      <th>health_expenditure</th>\n",
       "      <th>Income Group_Low income</th>\n",
       "      <th>Income Group_Lower middle income</th>\n",
       "      <th>Income Group_Upper middle income</th>\n",
       "      <th>host_flag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>AUS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AUS</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.132988</td>\n",
       "      <td>133.277267</td>\n",
       "      <td>106.240761</td>\n",
       "      <td>96.240000</td>\n",
       "      <td>107.031203</td>\n",
       "      <td>10.543639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>AUT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AUT</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.775627</td>\n",
       "      <td>101.458000</td>\n",
       "      <td>93.940071</td>\n",
       "      <td>93.614091</td>\n",
       "      <td>123.434807</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>BEL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BEL</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101.821136</td>\n",
       "      <td>143.163513</td>\n",
       "      <td>82.688202</td>\n",
       "      <td>94.007831</td>\n",
       "      <td>101.870773</td>\n",
       "      <td>11.042908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>BLR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BLR</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.711967</td>\n",
       "      <td>94.535896</td>\n",
       "      <td>70.867569</td>\n",
       "      <td>89.507331</td>\n",
       "      <td>123.447255</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.293083</td>\n",
       "      <td>109.334312</td>\n",
       "      <td>77.802292</td>\n",
       "      <td>92.834017</td>\n",
       "      <td>91.230625</td>\n",
       "      <td>11.154714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Country  gold_medal  silver_medal  bronze_medal  total_medal  \\\n",
       "0  2022.0     AUS         1.0           2.0           1.0          4.0   \n",
       "1  2022.0     AUT         7.0           7.0           4.0         18.0   \n",
       "2  2022.0     BEL         1.0           0.0           1.0          2.0   \n",
       "3  2022.0     BLR         0.0           2.0           0.0          2.0   \n",
       "4  2022.0     CAN         4.0           8.0          14.0         26.0   \n",
       "\n",
       "  type_olympic  host_flag Country_  gold_medal_sum  ...  \\\n",
       "0            w        0.0      AUS           172.0  ...   \n",
       "1            w        0.0      AUT            92.0  ...   \n",
       "2            w        0.0      BEL            45.0  ...   \n",
       "3            w        0.0      BLR            23.0  ...   \n",
       "4            w        0.0      CAN           150.0  ...   \n",
       "\n",
       "   primary_enrollment_ratio  secondary_enrollment_ratio  \\\n",
       "0                 99.132988                  133.277267   \n",
       "1                100.775627                  101.458000   \n",
       "2                101.821136                  143.163513   \n",
       "3                 94.711967                   94.535896   \n",
       "4                 96.293083                  109.334312   \n",
       "\n",
       "   tertiary_enrollment_ratio  internet_penetration  mobile_penetration  \\\n",
       "0                 106.240761             96.240000          107.031203   \n",
       "1                  93.940071             93.614091          123.434807   \n",
       "2                  82.688202             94.007831          101.870773   \n",
       "3                  70.867569             89.507331          123.447255   \n",
       "4                  77.802292             92.834017           91.230625   \n",
       "\n",
       "   health_expenditure  Income Group_Low income  \\\n",
       "0           10.543639                      0.0   \n",
       "1           12.100000                      0.0   \n",
       "2           11.042908                      0.0   \n",
       "3            6.570000                      0.0   \n",
       "4           11.154714                      0.0   \n",
       "\n",
       "   Income Group_Lower middle income Income Group_Upper middle income  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              0.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              1.0   \n",
       "4                               0.0                              0.0   \n",
       "\n",
       "   host_flag_1  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32c74518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features\n",
    "features = ['gold_medal', 'silver_medal', 'bronze_medal', 'NY.GDP.MKTP.CD', \n",
    "            'AG.LND.TOTL.K2', 'health_expenditure', 'gdp_population_interaction', \n",
    "            'SP.POP.TOTL', 'gdp_per_capita', 'SP.DYN.LE00.IN', 'tertiary_enrollment_ratio',\n",
    "            'urbanization_rate', 'internet_penetration', 'employment_to_population_ratio',\n",
    "            'gold_medal_mean', 'silver_medal_mean', 'bronze_medal_mean', 'total_medal_mean',\n",
    "            'host_flag_sum', 'Income Group_Low income', 'Income Group_Lower middle income',\n",
    "            'Income Group_Upper middle income', 'host_flag_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4dac62ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 60)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Country']!='USA']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "325fea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results\n",
      "                                  MAE        RÂ²\n",
      "Linear Regression            0.333069  0.997206\n",
      "Random Forest Regressor      2.106667  0.880511\n",
      "Gradient Boosting Regressor  2.162656  0.886555\n",
      "XGBoost                      1.644027  0.945845\n"
     ]
    }
   ],
   "source": [
    "# Define the target variable\n",
    "target = data['total_medal']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_poly_scaled = pipeline.fit_transform(data[features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "    #,\n",
    "    #'LightGBM': LGBMRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[model_name] = {'MAE': mae, 'RÂ²': r2}\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Display the evaluation results\n",
    "print(\"Model Evaluation Results\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdf96b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 20, 'min_samples_leaf': 2, 'max_depth': 5, 'learning_rate': 0.2}\n",
      "Tuned Gradient Boosting Regressor with Polynomial Features - MAE: 1.66, RÂ²: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Perform Randomized Search for hyperparameter tuning for Gradient Boosting Regressor\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8]\n",
    "}\n",
    "\n",
    "# Initialize and fit RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(GradientBoostingRegressor(random_state=42), param_dist, n_iter=100, cv=5, scoring='r2', n_jobs=-1, random_state=42)\n",
    "random_search.fit(X_train_poly, y_train)\n",
    "\n",
    "# Get the best parameters and train the refined model\n",
    "best_params_refined = random_search.best_params_\n",
    "best_gbr_model_refined = GradientBoostingRegressor(**best_params_refined, random_state=42)\n",
    "best_gbr_model_refined.fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred_best = best_gbr_model_refined.predict(X_test_poly)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Best Parameters: {best_params_refined}\")\n",
    "print(f\"Tuned Gradient Boosting Regressor with Polynomial Features - MAE: {mae_best:.2f}, RÂ²: {r2_best:.2f}\")\n",
    "#print(f\"Cross-validation RÂ²: {mean_cv_score:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0a295b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.8}\n",
      "Tuned XGBoost with Polynomial Features - MAE: 0.97, RÂ²: 0.98\n",
      "Cross-validation RÂ²: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=XGBRegressor(random_state=42), param_distributions=param_dist, n_iter=30, cv=5, scoring='r2', n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_poly, y_train)\n",
    "\n",
    "# Best parameters and model evaluation\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_poly)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(best_model, X_poly_scaled, target, cv=10, scoring='r2')\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Tuned XGBoost with Polynomial Features - MAE: {mae_best:.2f}, RÂ²: {r2_best:.2f}\")\n",
    "print(f\"Cross-validation RÂ²: {mean_cv_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e420ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "best_model.version = '1.0'\n",
    "best_model.pandas_version = pd.__version__\n",
    "best_model.numpy_version = np.__version__\n",
    "best_model.sklearn_version = sklearn.__version__\n",
    "best_model.X_columns = [col for col in enhanced_data[enhanced_features].columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64f7490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_model.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.2, max_depth=4, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=300, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.8; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9; total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "#modelpath = '../models'\n",
    "#save_file(best_model, 'ski_resort_pricing_model.pkl', modelpath)\n",
    "\n",
    "joblib.dump(best_model, '../models/best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644e902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
