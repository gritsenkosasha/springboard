{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3147fdfb",
   "metadata": {},
   "source": [
    "# Model Evaluation and Prediction\n",
    "This notebook contains the evaluation and prediction steps for the time series models predicting world population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d65dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from prophet import Prophet\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261a7dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AG.LND.AGRI.ZS</th>\n",
       "      <th>EG.CFT.ACCS.ZS</th>\n",
       "      <th>EG.ELC.ACCS.ZS</th>\n",
       "      <th>EN.POP.DNST</th>\n",
       "      <th>ER.H2O.INTR.PC</th>\n",
       "      <th>NY.GDP.MKTP.CD</th>\n",
       "      <th>NY.GDP.PCAP.CD</th>\n",
       "      <th>SE.ADT.LITR.ZS</th>\n",
       "      <th>SE.PRM.ENRL</th>\n",
       "      <th>SE.PRM.ENRL.TC.ZS</th>\n",
       "      <th>...</th>\n",
       "      <th>SP.POP.GROW</th>\n",
       "      <th>SP.POP.TOTL</th>\n",
       "      <th>SP.RUR.TOTL.ZS</th>\n",
       "      <th>SP.URB.TOTL.IN.ZS</th>\n",
       "      <th>GDP_per_Capita_lag1</th>\n",
       "      <th>Life_Expectancy_lag1</th>\n",
       "      <th>Crude_Birth_Rate_lag1</th>\n",
       "      <th>Pr_school_enrollment_lag1</th>\n",
       "      <th>Mortality_rate_lag1</th>\n",
       "      <th>Population_growth_rate_lag1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961-01-01</th>\n",
       "      <td>35.879317</td>\n",
       "      <td>49.296068</td>\n",
       "      <td>73.351057</td>\n",
       "      <td>28.528475</td>\n",
       "      <td>13632.001963</td>\n",
       "      <td>1.439319e+12</td>\n",
       "      <td>468.456801</td>\n",
       "      <td>65.586548</td>\n",
       "      <td>401658848.0</td>\n",
       "      <td>28.105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350895</td>\n",
       "      <td>3.072470e+09</td>\n",
       "      <td>65.910435</td>\n",
       "      <td>34.089565</td>\n",
       "      <td>450.106029</td>\n",
       "      <td>50.894331</td>\n",
       "      <td>31.908511</td>\n",
       "      <td>90.8022</td>\n",
       "      <td>17.234125</td>\n",
       "      <td>1.350895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-01-01</th>\n",
       "      <td>35.952470</td>\n",
       "      <td>49.296068</td>\n",
       "      <td>73.351057</td>\n",
       "      <td>29.033819</td>\n",
       "      <td>13395.564612</td>\n",
       "      <td>1.542845e+12</td>\n",
       "      <td>493.411159</td>\n",
       "      <td>65.586548</td>\n",
       "      <td>401658848.0</td>\n",
       "      <td>28.105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.771351</td>\n",
       "      <td>3.126894e+09</td>\n",
       "      <td>65.478880</td>\n",
       "      <td>34.521120</td>\n",
       "      <td>468.456801</td>\n",
       "      <td>52.846477</td>\n",
       "      <td>31.165497</td>\n",
       "      <td>90.8022</td>\n",
       "      <td>14.583294</td>\n",
       "      <td>1.350895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963-01-01</th>\n",
       "      <td>36.035383</td>\n",
       "      <td>49.296068</td>\n",
       "      <td>73.351057</td>\n",
       "      <td>29.651986</td>\n",
       "      <td>13109.723539</td>\n",
       "      <td>1.664977e+12</td>\n",
       "      <td>521.369208</td>\n",
       "      <td>65.586548</td>\n",
       "      <td>401658848.0</td>\n",
       "      <td>28.105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.129136</td>\n",
       "      <td>3.193470e+09</td>\n",
       "      <td>65.102013</td>\n",
       "      <td>34.897987</td>\n",
       "      <td>493.411159</td>\n",
       "      <td>55.208783</td>\n",
       "      <td>35.103391</td>\n",
       "      <td>90.8022</td>\n",
       "      <td>13.616499</td>\n",
       "      <td>1.771351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964-01-01</th>\n",
       "      <td>36.117043</td>\n",
       "      <td>49.296068</td>\n",
       "      <td>73.351057</td>\n",
       "      <td>30.274183</td>\n",
       "      <td>12834.164741</td>\n",
       "      <td>1.827785e+12</td>\n",
       "      <td>560.587725</td>\n",
       "      <td>65.586548</td>\n",
       "      <td>401658848.0</td>\n",
       "      <td>28.105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.098330</td>\n",
       "      <td>3.260480e+09</td>\n",
       "      <td>64.717882</td>\n",
       "      <td>35.282118</td>\n",
       "      <td>521.369208</td>\n",
       "      <td>55.542430</td>\n",
       "      <td>36.274663</td>\n",
       "      <td>90.8022</td>\n",
       "      <td>13.459129</td>\n",
       "      <td>2.129136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965-01-01</th>\n",
       "      <td>36.213941</td>\n",
       "      <td>49.296068</td>\n",
       "      <td>73.351057</td>\n",
       "      <td>30.903380</td>\n",
       "      <td>12566.777472</td>\n",
       "      <td>1.990240e+12</td>\n",
       "      <td>597.985077</td>\n",
       "      <td>65.586548</td>\n",
       "      <td>401658848.0</td>\n",
       "      <td>28.105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.078320</td>\n",
       "      <td>3.328243e+09</td>\n",
       "      <td>64.500479</td>\n",
       "      <td>35.499521</td>\n",
       "      <td>560.587725</td>\n",
       "      <td>56.034953</td>\n",
       "      <td>35.131852</td>\n",
       "      <td>90.8022</td>\n",
       "      <td>13.529275</td>\n",
       "      <td>2.098330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AG.LND.AGRI.ZS  EG.CFT.ACCS.ZS  EG.ELC.ACCS.ZS  EN.POP.DNST  \\\n",
       "Year                                                                      \n",
       "1961-01-01       35.879317       49.296068       73.351057    28.528475   \n",
       "1962-01-01       35.952470       49.296068       73.351057    29.033819   \n",
       "1963-01-01       36.035383       49.296068       73.351057    29.651986   \n",
       "1964-01-01       36.117043       49.296068       73.351057    30.274183   \n",
       "1965-01-01       36.213941       49.296068       73.351057    30.903380   \n",
       "\n",
       "            ER.H2O.INTR.PC  NY.GDP.MKTP.CD  NY.GDP.PCAP.CD  SE.ADT.LITR.ZS  \\\n",
       "Year                                                                         \n",
       "1961-01-01    13632.001963    1.439319e+12      468.456801       65.586548   \n",
       "1962-01-01    13395.564612    1.542845e+12      493.411159       65.586548   \n",
       "1963-01-01    13109.723539    1.664977e+12      521.369208       65.586548   \n",
       "1964-01-01    12834.164741    1.827785e+12      560.587725       65.586548   \n",
       "1965-01-01    12566.777472    1.990240e+12      597.985077       65.586548   \n",
       "\n",
       "            SE.PRM.ENRL  SE.PRM.ENRL.TC.ZS  ...  SP.POP.GROW   SP.POP.TOTL  \\\n",
       "Year                                        ...                              \n",
       "1961-01-01  401658848.0             28.105  ...     1.350895  3.072470e+09   \n",
       "1962-01-01  401658848.0             28.105  ...     1.771351  3.126894e+09   \n",
       "1963-01-01  401658848.0             28.105  ...     2.129136  3.193470e+09   \n",
       "1964-01-01  401658848.0             28.105  ...     2.098330  3.260480e+09   \n",
       "1965-01-01  401658848.0             28.105  ...     2.078320  3.328243e+09   \n",
       "\n",
       "            SP.RUR.TOTL.ZS  SP.URB.TOTL.IN.ZS  GDP_per_Capita_lag1  \\\n",
       "Year                                                                 \n",
       "1961-01-01       65.910435          34.089565           450.106029   \n",
       "1962-01-01       65.478880          34.521120           468.456801   \n",
       "1963-01-01       65.102013          34.897987           493.411159   \n",
       "1964-01-01       64.717882          35.282118           521.369208   \n",
       "1965-01-01       64.500479          35.499521           560.587725   \n",
       "\n",
       "            Life_Expectancy_lag1  Crude_Birth_Rate_lag1  \\\n",
       "Year                                                      \n",
       "1961-01-01             50.894331              31.908511   \n",
       "1962-01-01             52.846477              31.165497   \n",
       "1963-01-01             55.208783              35.103391   \n",
       "1964-01-01             55.542430              36.274663   \n",
       "1965-01-01             56.034953              35.131852   \n",
       "\n",
       "            Pr_school_enrollment_lag1  Mortality_rate_lag1  \\\n",
       "Year                                                         \n",
       "1961-01-01                    90.8022            17.234125   \n",
       "1962-01-01                    90.8022            14.583294   \n",
       "1963-01-01                    90.8022            13.616499   \n",
       "1964-01-01                    90.8022            13.459129   \n",
       "1965-01-01                    90.8022            13.529275   \n",
       "\n",
       "            Population_growth_rate_lag1  \n",
       "Year                                     \n",
       "1961-01-01                     1.350895  \n",
       "1962-01-01                     1.350895  \n",
       "1963-01-01                     1.771351  \n",
       "1964-01-01                     2.129136  \n",
       "1965-01-01                     2.098330  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '../data/processed/data_fe.csv'\n",
    "data = pd.read_csv(file_path,parse_dates=['Year'],index_col='Year')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3947d610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 6), (11, 6), (49,), (11,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the features and target variable\n",
    "features =['GDP_per_Capita_lag1', 'Life_Expectancy_lag1', 'Crude_Birth_Rate_lag1',\\\n",
    "           'Pr_school_enrollment_lag1','Mortality_rate_lag1','Population_growth_rate_lag1']\n",
    "\n",
    "#X = data[features]\n",
    "X = data[features]\n",
    "y = data['SP.POP.TOTL']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split_year = '2010-01-01'\n",
    "X_train = X[X.index < split_year]\n",
    "X_test = X[X.index >= split_year]\n",
    "y_train = y[y.index < split_year]\n",
    "y_test = y[y.index >= split_year]\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5eff96",
   "metadata": {},
   "source": [
    "### ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113c93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency AS-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency AS-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency AS-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6900836792.350409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the ARIMA model\n",
    "arima_model = sm.tsa.ARIMA(y_train, order=(5, 1, 0))\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Make predictions\n",
    "arima_predictions = arima_model_fit.forecast(steps=len(y_test))[0]\n",
    "\n",
    "# Display the predictions\n",
    "display(arima_predictions)\n",
    "\n",
    "\n",
    "# Calculate MAE and MSE for ARIMA model\n",
    "#arima_mae = mean_absolute_error(y_test, arima_predictions)\n",
    "#arima_mse = mean_squared_error(y_test, arima_predictions)\n",
    "\n",
    "#(arima_mae, arima_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23e0959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency AS-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency AS-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:1009: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 5697944.196465492\n",
      "Mean Squared Error (MSE): 32466568066034.785\n",
      "Year\n",
      "2020-01-01    7.826970e+09\n",
      "Name: predicted_population, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sarima_data=data\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data = sarima_data[sarima_data.index < '2020-01-01']\n",
    "test_data = sarima_data[sarima_data.index >= '2020-01-01']\n",
    "\n",
    "# Fit the SARIMA model\n",
    "sarima_model = SARIMAX(train_data['SP.POP.TOTL'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "\n",
    "# Make predictions\n",
    "start_index = test_data.index[0]\n",
    "end_index = test_data.index[-1]\n",
    "sarima_predictions = sarima_result.predict(start=start_index, end=end_index, typ='levels')\n",
    "\n",
    "# Combine actual and predicted values\n",
    "sarima_results = test_data.copy()\n",
    "sarima_results['predicted_population'] = sarima_predictions\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "sarima_mae = mean_absolute_error(sarima_results['SP.POP.TOTL'], sarima_results['predicted_population'])\n",
    "sarima_mse = mean_squared_error(sarima_results['SP.POP.TOTL'], sarima_results['predicted_population'])\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {sarima_mae}')\n",
    "print(f'Mean Squared Error (MSE): {sarima_mse}')\n",
    "\n",
    "print(sarima_results['predicted_population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8288bff",
   "metadata": {},
   "source": [
    "### Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266709b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:18:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:19:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 25428414.68296155\n",
      "Mean Squared Error (MSE): 798590186396194.5\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for Prophet\n",
    "train_df = y_train.reset_index()\n",
    "train_df.columns = ['ds', 'y']\n",
    "\n",
    "# Train the Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(train_df)\n",
    "\n",
    "# Make future dataframe for predictions\n",
    "future = prophet_model.make_future_dataframe(periods=len(y_test), freq='AS')\n",
    "\n",
    "# Make predictions\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "prophet_predictions = prophet_forecast['yhat'][-len(y_test):].values\n",
    "\n",
    "# Calculate MAE and MSE for Prophet model\n",
    "prophet_mae = mean_absolute_error(y_test, prophet_predictions)\n",
    "prophet_mse = mean_squared_error(y_test, prophet_predictions)\n",
    "\n",
    "(prophet_mae, prophet_mse)\n",
    "# Display evaluation metrics\n",
    "print(f'Mean Absolute Error (MAE): {prophet_mae}')\n",
    "print(f'Mean Squared Error (MSE): {prophet_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0659b02",
   "metadata": {},
   "source": [
    "###  LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd5b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 24521732734148673536.0000 \n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21453840205955989504.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25951297961373728768.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24877455532059787264.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 24587180064280412160.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27801351619432415232.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 25612043648623443968.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26287926640356884480.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 25913663877378211840.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 27062255505194876928.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26511930144283688960.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 26548732997488607232.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 25124784075658231808.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23892187560456224768.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 24665650010131529728.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23738447247590817792.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24609319830417309696.0000 \n",
      "Epoch 18/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22519478079503466496.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24772619297374601216.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27541820695788912640.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28106650814093721600.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25454773903432876032.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27727954820231856128.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24094922111455330304.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28430925380427186176.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24918374956799098880.0000 \n",
      "Epoch 27/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24687105880035950592.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26579552308415168512.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27161040027880783872.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26756837563277770752.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23480095000412291072.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24523835000380981248.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25562266558210768896.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25904364208030482432.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27732172546836004864.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 28164689634877505536.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 26488011368333049856.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 26593738207436734464.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26051047855268823040.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 24455581716575158272.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - loss: 26358554869278703616.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 27359607429810618368.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26216203297853800448.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26009580873738878976.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24372845665608269824.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24778407126583214080.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24023957431975411712.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27130486798768144384.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27140613300859961344.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28471528145817698304.0000 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Mean Absolute Error (MAE): 7573542240.404526\n",
      "Mean Squared Error (MSE): 5.738694536732187e+19\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for LSTM\n",
    "def create_dataset(X, y, time_step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)-time_step-1):\n",
    "        Xs.append(X[i:(i+time_step), :])\n",
    "        ys.append(y[i + time_step])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_step = 3\n",
    "X_train_lstm, y_train_lstm = create_dataset(X_train.values, y_train.values, time_step)\n",
    "X_test_lstm, y_test_lstm = create_dataset(X_test.values, y_test.values, time_step)\n",
    "\n",
    "# Define the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, return_sequences=True, input_shape=(time_step, X_train_lstm.shape[2])))\n",
    "lstm_model.add(LSTM(50, return_sequences=False))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=1, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "lstm_predictions = lstm_model.predict(X_test_lstm)\n",
    "\n",
    "# Reshape the predictions to match the shape of y_test\n",
    "lstm_predictions = lstm_predictions.flatten()\n",
    "\n",
    "# Calculate MAE and MSE for LSTM model\n",
    "lstm_mae = mean_absolute_error(y_test[-len(lstm_predictions):], lstm_predictions)\n",
    "lstm_mse = mean_squared_error(y_test[-len(lstm_predictions):], lstm_predictions)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {lstm_mae}')\n",
    "print(f'Mean Squared Error (MSE): {lstm_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067ed62",
   "metadata": {},
   "source": [
    "### Select Best Model and Predict for 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "687865e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:19:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "21:19:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7916023533.334709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on the evaluation metrics, select the best model \n",
    "\n",
    "# Prepare the entire dataset for Prophet\n",
    "all_data_df = y.reset_index()\n",
    "all_data_df.columns = ['ds', 'y']\n",
    "\n",
    "# Train the Prophet model on the entire dataset\n",
    "final_prophet_model = Prophet()\n",
    "final_prophet_model.fit(all_data_df)\n",
    "\n",
    "# Make future dataframe for 2020 prediction\n",
    "future_final = final_prophet_model.make_future_dataframe(periods=1, freq='AS')\n",
    "\n",
    "# Make prediction for 2020\n",
    "final_forecast = final_prophet_model.predict(future_final)\n",
    "population_2020 = final_forecast['yhat'].values[-1]\n",
    "\n",
    "population_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dabd895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7821272000.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.821272e+09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
